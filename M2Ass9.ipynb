{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922aaa5e-6708-4e69-9e7a-205907503d9c",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95346e-f719-4cd8-8ffd-2104f7beb999",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21fb30-a369-415b-bf0d-bcc9febe6624",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two common ways to describe the probability distribution of a random variable.\n",
    "\n",
    "The PMF is used for discrete random variables, which take on a countable set of possible values. It gives the probability that the random variable takes on a specific value. The PMF is defined as:\n",
    "\n",
    "PMF(x) = P(X = x)\n",
    "where X is the random variable and x is a possible value it can take on. The PMF satisfies the following properties:\n",
    "\n",
    "PMF(x) >= 0 for all possible values of x.\n",
    "The sum of PMF(x) over all possible values of x is equal to 1.\n",
    "For example, consider a fair six-sided die. The random variable X represents the number that comes up when the die is rolled. The PMF of X is:\n",
    "PMF(1) = 1/6\n",
    "PMF(2) = 1/6\n",
    "PMF(3) = 1/6\n",
    "PMF(4) = 1/6\n",
    "PMF(5) = 1/6\n",
    "PMF(6) = 1/6\n",
    "PDF(x) = d/dx CDF(x)\n",
    "where CDF(x) is the probability that the random variable takes on a value less than or equal to x. The PDF satisfies the following properties:\n",
    "\n",
    "PDF(x) >= 0 for all possible values of x.\n",
    "The area under the PDF over any interval is equal to the probability that the random variable falls in that interval.\n",
    "PDF(x) = (1/sqrt(2*pi)) * exp(-x^2/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16e837-c1e6-4fb9-ac6b-df42ec364ef1",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293a616-41dd-4410-b15b-ac253ce70101",
   "metadata": {},
   "source": [
    "Cumulative Density Function (CDF) is a statistical function that shows the cumulative probability distribution of a random variable. It gives the probability that a random variable X is less than or equal to a certain value x. The CDF is defined as the integral of the probability density function (PDF) of X from negative infinity to x.\n",
    "\n",
    "For example, suppose we have a random variable X that represents the height of students in a class. The CDF of X would give the probability that a student's height is less than or equal to a certain value. If we know that the mean height of the class is 5 feet 8 inches and the standard deviation is 2 inches, we can use the CDF to find the probability that a student is less than or equal to 6 feet tall.\n",
    "\n",
    "CDF is used for many purposes, including:\n",
    "\n",
    "Estimating the probability that a random variable X takes on a certain value or falls within a certain range.\n",
    "\n",
    "Comparing two or more probability distributions.\n",
    "\n",
    "Calculating percentiles, such as the median or quartiles, which divide a distribution into equal parts.\n",
    "\n",
    "Evaluating the goodness of fit of a probability distribution to a set of data.\n",
    "\n",
    "CDF is a powerful tool in statistical analysis and can be used in a variety of fields, including economics, engineering, and biology, to name a few."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209d9fb-d89e-4c34-a344-d146aaf9f4da",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b5d6c-ebc1-4fc8-a946-95b4f78ba17f",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a widely used probability distribution that describes many natural phenomena. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "​\n",
    "Height and weight: The distribution of height and weight in a population is often modeled using the normal distribution.\n",
    "​\n",
    "Test scores: The scores on standardized tests, such as the SAT or GRE, are often modeled using the normal distribution.\n",
    "​\n",
    "Errors in measurement: Errors in measurement, such as in laboratory experiments, are often assumed to be normally distributed.\n",
    "​\n",
    "Financial data: Stock prices, interest rates, and other financial data are often modeled using the normal distribution.\n",
    "​\n",
    "The normal distribution has two parameters: the mean, denoted by µ, and the standard deviation, denoted by σ. These parameters determine the shape of the distribution. Specifically:\n",
    "​\n",
    "The mean µ determines the location of the center of the distribution. The normal distribution is symmetric around the mean.\n",
    "​\n",
    "The standard deviation σ determines the spread of the distribution. If σ is small, the distribution is narrow and peaked. If σ is large, the distribution is wide and flat.\n",
    "​\n",
    "The area under the curve of the normal distribution is always equal to 1, and the total area between any two points on the curve represents the probability of an event occurring within that range. The normal distribution is a powerful tool in statistics and is used to model many different phenomena in the natural world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15081d5-9e43-4e3e-8eb4-1c2dfaac35b8",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795d83c-5c1d-4fb5-8ae9-d306005f44c9",
   "metadata": {},
   "source": [
    "The normal distribution is important in statistics because it is the most commonly used probability distribution. It is used to model a wide variety of natural phenomena, and it has several properties that make it particularly useful for statistical analysis. Some of the key properties of the normal distribution include:\n",
    "\n",
    "Symmetry: The normal distribution is symmetric, which means that the mean, median, and mode are all equal.\n",
    "\n",
    "Central limit theorem: The sum or average of a large number of independent and identically distributed random variables tends to follow the normal distribution, regardless of the distribution of the individual variables.\n",
    "\n",
    "Parameterization: The normal distribution is parameterized by two parameters, the mean and the standard deviation, which are easy to interpret and estimate from data.\n",
    "\n",
    "Here are some real-life examples of normal distribution:\n",
    "\n",
    "Height: The distribution of human heights follows the normal distribution. The mean height for men in the United States is about 5 feet 9 inches, and the standard deviation is about 3 inches.\n",
    "\n",
    "IQ scores: IQ scores are standardized to have a mean of 100 and a standard deviation of 15. The distribution of IQ scores follows the normal distribution.\n",
    "\n",
    "Weight: The distribution of weights of products coming off a production line is often assumed to follow the normal distribution.\n",
    "\n",
    "Blood pressure: The distribution of blood pressure in a population is often modeled using the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285c09b-527a-44e5-bae1-fd52836495d8",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0fca2-c3a3-4429-943a-bdefb6dc6769",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a single experiment with two possible outcomes: success or failure. It is named after Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, denoted by p, which represents the probability of success. The probability mass function of the Bernoulli distribution is:\n",
    "\n",
    "P(X = 1) = p\n",
    "\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is a random variable representing the outcome of the experiment.\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a coin. If we define success as getting heads, then the probability of success is p = 0.5. If we flip the coin once, the outcome is either heads (success) or tails (failure), so the random variable X can take on values of either 1 (success) or 0 (failure).\n",
    "\n",
    "The binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. The binomial distribution is characterized by two parameters: the number of trials, denoted by n, and the probability of success, denoted by p. The probability mass function of the binomial distribution is:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c60cd-6b9f-4041-91f8-fc97f524c626",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0343e-3f65-4485-bfe8-89574a057b26",
   "metadata": {},
   "source": [
    "To calculate the probability that a randomly selected observation from a normal distribution with a mean of 50 and a standard deviation of 10 will be greater than 60, we need to use the standard normal distribution. We first need to standardize the value 60 by converting it to a z-score using the formula:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where x is the value we want to standardize, mu is the mean of the distribution, and sigma is the standard deviation of the distribution.\n",
    "\n",
    "Substituting the values given in the problem, we have:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "We can then use a standard normal distribution table or calculator to find the probability that a randomly selected observation from a standard normal distribution will be greater than 1. The probability can also be calculated using the standard normal distribution formula:\n",
    "\n",
    "P(Z > 1) = 1 - P(Z < 1)\n",
    "\n",
    "where Z is a standard normal random variable.\n",
    "\n",
    "Using a standard normal distribution table or calculator, we find that the probability of Z being less than 1 is 0.8413. Therefore, the probability of Z being greater than 1 is:\n",
    "\n",
    "P(Z > 1) = 1 - 0.8413 = 0.1587"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ceda1-482a-4238-bbc2-61ed9c7e705a",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7efc0b-1040-4137-bfd2-d98bd266480b",
   "metadata": {},
   "source": [
    "Uniform distribution is a continuous probability distribution in which all values within a specified range are equally likely to occur. The probability density function (PDF) of a uniform distribution is a constant function between two values a and b, and zero elsewhere. The notation for a uniform distribution is U(a, b).\n",
    "\n",
    "For example, suppose we have a spinner that can land on any number between 1 and 10 with equal probability. The outcome of spinning the spinner can be modeled using a uniform distribution U(1, 10). The probability density function of this distribution would be:\n",
    "\n",
    "f(x) = 1/9 for 1 ≤ x ≤ 10\n",
    "\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "This means that any number between 1 and 10 is equally likely to be the outcome of spinning the spinner, and the probability of any specific value is the same.\n",
    "\n",
    "Another example of a uniform distribution is the height of a tree in a forest. If we assume that the height of a tree can range between 10 meters and 20 meters with equal probability, we can model the height of a tree using a uniform distribution U(10, 20). The probability density function of this distribution would be:\n",
    "\n",
    "f(x) = 1/10 for 10 ≤ x ≤ 20\n",
    "\n",
    "f(x) = 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271ab30-02c6-4778-a6f6-27b02c5bb72f",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7c23e-de1c-469d-9f91-29d5970b21f1",
   "metadata": {},
   "source": [
    "A z-score, also known as a standard score, is a measure of how many standard deviations an observation or data point is above or below the mean of a population or sample. It is calculated using the formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the mean of the population or sample, and σ is the standard deviation of the population or sample.\n",
    "\n",
    "The z-score is important because it provides a standardized way of comparing observations from different populations or samples. By converting data points to z-scores, we can compare them on the same scale and calculate probabilities associated with different values.\n",
    "\n",
    "For example, suppose we have two different datasets with different units of measurement, such as height in centimeters and weight in pounds. We cannot directly compare the values from these datasets because they are on different scales. However, by converting the values to z-scores, we can compare them on the same scale and determine which value is more unusual or extreme relative to its own population or sample.\n",
    "\n",
    "Another use of z-scores is in hypothesis testing and statistical inference. By calculating the z-score for a particular sample mean, we can determine the probability of observing that mean under the null hypothesis that the true population mean is a certain value. This can help us make decisions about whether to reject or fail to reject the null hypothesis based on the level of statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf417e-526d-40f3-b020-6d56e3e6af11",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8f38d-d8e3-46b9-883b-1e8fb1d64366",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the distribution of the population from which the sample is taken.\n",
    "\n",
    "In other words, if we take random samples of a population, the distribution of the means of those samples will be approximately normally distributed, even if the population itself is not normally distributed. This applies to any population, regardless of its shape or size.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make inferences about a population based on a sample. By using the distribution of sample means, we can estimate population parameters such as the mean and standard deviation, even if we do not know the true population parameters.\n",
    "\n",
    "The Central Limit Theorem is also important in hypothesis testing and statistical inference. For example, it allows us to calculate confidence intervals and test hypotheses about population means using the normal distribution, even if the population is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318174e-367d-450b-8610-119fb351b636",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bf760-d315-4af0-b615-c550de2db476",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the distribution of the population from which the sample is taken. The following are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "Independence: The sample observations should be independent of each other. That is, the value of one observation should not depend on the value of any other observation in the sample.\n",
    "\n",
    "Sample Size: The sample size should be sufficiently large. Although there is no hard and fast rule about the minimum sample size required for the CLT to apply, a general guideline is that the sample size should be at least 30.\n",
    "\n",
    "Population Distribution: The population from which the sample is drawn should have a finite mean (μ) and finite variance (σ²). If the population is not normal, it can still satisfy the CLT if the sample size is large enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
